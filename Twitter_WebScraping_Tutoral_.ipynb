{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Sample Tutorial: Web scraping Twitter**"
      ],
      "metadata": {
        "id": "OK5CaLcICJqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://developer.x.com/en/docs/tutorials/step-by-step-guide-to-making-your-first-request-to-the-twitter-api-v2\n",
        "\n",
        "\n",
        "https://developer.x.com/en/portal/dashboard\n",
        "\n",
        "\n",
        "**In dashboard, By default if you have project, Thats fine.\n",
        "Find all keys and copy and put in notepad.\n",
        "**\n",
        "\n",
        "Make sure you download your tweets and save csv file for next steps."
      ],
      "metadata": {
        "id": "VgSAmfDgSVBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tweepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbjq8JrPAiZU",
        "outputId": "d9b5579e-5f9f-48bb-8e3f-10b54846216a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.11/dist-packages (4.14.0)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tweepy** is a Python library for interacting with the **Twitter API**. It allows you to **search tweets, post tweets, fetch user data, manage followers, and more** using Twitter's API.  \n",
        "\n",
        "### Key Features:\n",
        "- Retrieve tweets, user profiles, and trends.\n",
        "- Post tweets and interact with them (like, retweet, reply).\n",
        "- Stream real-time tweets.\n",
        "- Use Twitter API v2 for advanced search queries.  \n",
        "\n",
        "It's commonly used for **Twitter automation, data analysis, and machine learning projects**. üöÄ\n",
        "https://docs.tweepy.org/en/stable/install.html"
      ],
      "metadata": {
        "id": "Hwcdx1F_r_Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "\n",
        "# Set your keys and tokens here\n",
        "api_key = 'z0teFMVcrHZPiDN7zUa6AdHBW'\n",
        "api_key_secret = 'fzi3QYxoLwK56PHryIO6IrhfgwKdKxhopvEbN7lgJgk7Jdz7xu'\n",
        "access_token = '1693819883547435008-uKctWAHtw0soND5lX0lvfIXgDDCly1'\n",
        "access_token_secret = 'UdtSW1g4nSSbjENXHIqrIerjZsXsnqYrW9EfWiHMAhTii'\n",
        "\n",
        "# Authenticate with Twitter\n",
        "auth = tweepy.OAuth1UserHandler(\n",
        "    consumer_key=api_key,\n",
        "    consumer_secret=api_key_secret,\n",
        "    access_token=access_token,\n",
        "    access_token_secret=access_token_secret\n",
        ")\n",
        "api = tweepy.API(auth)\n"
      ],
      "metadata": {
        "id": "Wex07-DsCI_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for tweets containing the #llm hashtag or any tag related to Machine Learning or AI specific Terms\n",
        "hashtag = '#llm'\n",
        "max_tweets = 100  # Adjust based on how many tweets you want to scrape\n",
        "\n",
        "tweets = tweepy.Cursor(api.search_tweets, q=hashtag, lang=\"en\", tweet_mode=\"extended\").items(max_tweets)\n",
        "\n",
        "# Store the tweets\n",
        "tweet_data = []\n",
        "\n",
        "for tweet in tweets:\n",
        "    tweet_data.append({\n",
        "        'tweet_id': tweet.id,\n",
        "        'created_at': tweet.created_at,\n",
        "        'user': tweet.user.screen_name,\n",
        "        'text': tweet.full_text\n",
        "    })\n",
        "\n",
        "# Display the collected tweet data\n",
        "for tweet in tweet_data:\n",
        "    print(f\"@{tweet['user']}: {tweet['text']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "qFFB3VtaCmkA",
        "outputId": "0f380fd1-1e92-4e80-b492-a53f6ae6ac24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Forbidden",
          "evalue": "403 Forbidden\n453 - You currently have access to a subset of X API V2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.x.com/en/portal/product",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d0757528022d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtweet_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     tweet_data.append({\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m'tweet_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             model = ModelParser().parse(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpagination_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payload_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payload_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36msearch_tweets\u001b[0;34m(self, q, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0m_Twitter\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0msearch\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdeveloper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0moverview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \"\"\"\n\u001b[0;32m-> 1146\u001b[0;31m         return self.request(\n\u001b[0m\u001b[1;32m   1147\u001b[0m             'GET', 'search/tweets', endpoint_parameters=(\n\u001b[1;32m   1148\u001b[0m                 \u001b[0;34m'q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'geocode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lang'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'locale'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mUnauthorized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m403\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mForbidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mForbidden\u001b[0m: 403 Forbidden\n453 - You currently have access to a subset of X API V2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.x.com/en/portal/product"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The \"hastags (#)\" for search must be related to Machine learning , Deep Learning and AI (related topic only)**"
      ],
      "metadata": {
        "id": "E0PAN9qpqheF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**#Here i have used -is:retweets (which excludes all retweets) in query, please use CHATGPT for unique query..**"
      ],
      "metadata": {
        "id": "EryxN_K9rlG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "\n",
        "# Set up client with bearer token\n",
        "client = tweepy.Client(bearer_token='AAAAAAAAAAAAAAAAAAAAAJZRygEAAAAAyHYcQD%2F6Ihofv77BE%2FJUP3Tg3J8%3DA8U5L7bHBZbi2FGpQKS3MPQxMVKsUTifSyB1QNARzIysk2GdxI')\n",
        "\n",
        "# Search for tweets with hashtag #llm\n",
        "\n",
        "#here i have used -is:retweets (which excludes all retweets), please use CHATGPT for unique query..\n",
        "\n",
        "query = \"#llm -is:retweet\"\n",
        "tweets = client.search_recent_tweets(query=query, tweet_fields=[\"created_at\", \"text\", \"author_id\"], max_results=100)\n",
        "\n",
        "# Print tweets\n",
        "for tweet in tweets.data:\n",
        "    print(f\"User: {tweet.author_id}, Tweet: {tweet.text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nfTFVIjDAtA",
        "outputId": "f8f11919-8387-4ce0-ea05-63cef45759fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: 3287978395, Tweet: I bet satya is already booking his flight to China \n",
            "#DeepSeek\n",
            "#AI #LLM #openAI #Microsoft #ChatGPT https://t.co/c6DsNEPS1n\n",
            "User: 547930501, Tweet: Current #AI &amp; #LLM case, @OpenAI vs. @deepseek_ai, from a product lifecycle perspective? Classic.\n",
            "\n",
            "#USA paid for and invented the whole thing.\n",
            "#China copied it and used it for propaganda.\n",
            "#EU don‚Äôt understand it, so at least they try to regulate it.\n",
            "\n",
            "https://t.co/9R8v8e5P7s\n",
            "User: 547930501, Tweet: Aktu√°ln√≠ #AI &amp; #LLM kauza @OpenAI vs. @deepseek_ai z pohledu produktov√©ho ≈æivotn√≠ho cyklu? Klasika.\n",
            "\n",
            "V #USA to cel√© zaplatili a vymysleli.\n",
            "V #China to okop√≠rovali a vyu≈æ√≠vaj√≠ k propagandƒõ. \n",
            "V #EU tomu nerozum√≠, tak se to aspo≈à pokou≈°ej√≠ regulovat.\n",
            "\n",
            "üåê https://t.co/9R8v8e5P7s https://t.co/jAKINJWBEB https://t.co/V4kpAcVqKQ\n",
            "User: 2850298501, Tweet: ÿ±ŸÇÿßÿ®ÿ™ #llm Ÿáÿß ÿ∑Ÿàÿ±€å Ÿáÿ≥ÿ™ ⁄©Ÿá ÿØÿ± ÿ¢€åŸÜÿØŸá ŸÜÿ≤ÿØ€å⁄© ÿ®ŸáŸÖŸàŸÜ ŸæŸàŸÑ ŸáŸÖ ŸÖ€åÿØŸÜ ⁄©Ÿá ÿßÿ≤ ⁄Üÿ™ ÿ®ÿßÿ®ÿ™ ÿ¥ŸàŸÜ ÿßÿ≥ÿ™ŸÅÿßÿØŸá \n",
            "⁄©ŸÜ€åŸÖüòâ\n",
            "User: 1893098202, Tweet: Qu√© es Ollama y c√≥mo usarlo para instalar en tu ordenador modelos de inteligencia artificial como Llama, DeepSeek y m√°s https://t.co/CM0qM06emM @xataka #ollama #AI #LLM\n",
            "User: 802246546607644672, Tweet: üëÅÔ∏èüëÅÔ∏èIn an ironic twist, #OpenAI is purportedly shocked that an #AI company would train on someone else's #data without permission or #compensation.\n",
            "\n",
            "#DeepSeekR1 #LLM #Ethics  #artists #VoiceActors @NAVAVOICES @tantriclens @Shi4Tech @pierrepinna @Nicochan33 https://t.co/ajaIUknXi3\n",
            "User: 267334359, Tweet: LLM Shotgun is live. Stop guessing. Start knowing.\n",
            "\n",
            "GPT, Claude, DeepSeek‚Äîeveryone‚Äôs got a favorite. But which one actually works for you?\n",
            "\n",
            "Use https://t.co/aVtKcVkhyR and get a straight answer.\n",
            "\n",
            "AI isn‚Äôt here to take your job. It‚Äôs here to make it easier. Your move.\n",
            "\n",
            "#AI #LLM\n",
            "User: 1169697972, Tweet: ü´µ https://t.co/gOsgK4BPyv\n",
            "\n",
            "¬ª3 Questions: Modeling adversarial intelligence to exploit AI‚Äôs security vulnerabilities¬´ https://t.co/HTXP8wa2Er #AIagent #AI #ML #NLP #LLM #GenAI\n",
            "User: 1017442557591093249, Tweet: How DeepSeek  üß†Outperforms the Competition: 5 Key Advantages in the AI Race üåÄ\n",
            "\n",
            "https://t.co/I42IxuHTg6\n",
            "\n",
            "#ai #DeepLearning #artificialintelligence #opensource #TechInnovation #AIResearch #FutureOfAI #LLM #aicommunity #ShopifyStore  #OpenSourceAI  #futuretech #shopify\n",
            "User: 1819856415022088192, Tweet: Despite what it looks like, we‚Äôve plateaued. And when you plateau, others catch up‚Äîfast.\n",
            "\n",
            "OpenAI is running out of ideas. The ‚Äòjust throw more data at it‚Äô era is ending. This is good for the industry. We need diverse ML techniques, not one overhyped theory.\n",
            "\n",
            "#MachineLearning #LLM\n",
            "User: 1495675084836675584, Tweet: Œ£œÖŒΩŒ≠ŒΩœÑŒµœÖŒæŒ∑ œÉœÑŒø Œ∫Œ±ŒΩŒ¨ŒªŒπ œÑŒ∑œÇ ŒùŒ±œÖœÑŒµŒºœÄŒøœÅŒπŒ∫ŒÆœÇ (29/1/2025) œÉœáŒµœÑŒπŒ∫Œ¨ ŒºŒµ œÑŒπœÇ ŒµŒæŒµŒªŒØŒæŒµŒπœÇ œÉœÑŒ∑ŒΩ Œ§ŒµœáŒΩŒ∑œÑŒÆ ŒùŒøŒ∑ŒºŒøœÉœçŒΩŒ∑ Œ∫Œ±Œπ œÑŒπ œÉŒ∑ŒºŒ±œÑŒøŒ¥ŒøœÑŒµŒØ œÑŒø #DeepSeek œÉœÑŒø œÄŒµŒ¥ŒØŒø œÑœâŒΩ ŒµœÜŒ±œÅŒºŒøŒ≥œéŒΩ œÑœâŒΩ ŒºŒøŒΩœÑŒ≠ŒªœâŒΩ LLMs.\n",
            "&gt;&gt; https://t.co/jRnNcsVSJW\n",
            "---\n",
            "#ŒïŒ†Œï #HIU #Œ†ŒªŒ∑œÅŒøœÜŒøœÅŒπŒ∫ŒÆ #œÉœÖŒΩŒµŒΩœÑŒµœÖŒæŒµŒπœÇ #AI #artificialintelligence #llm\n",
            "User: 1679879671889145856, Tweet: Totday's Portfolio Summary\n",
            "#StockMarkets #Arduino #ESP32 #Raspberrypi #Chihuahua #Stocks #Hodl #Python #Alpaca #Ollama #LLama3 #LLM #GPT https://t.co/gyTATguhv8\n",
            "User: 1169697972, Tweet: ü´µ https://t.co/gOsgK4BPyv\n",
            "\n",
            "¬ªMIT students' works redefine human-AI collaboration¬´ https://t.co/KFGhfhFXSW #AIagent #AI #ML #NLP #LLM #GenAI\n",
            "User: 1817088852122587136, Tweet: Exciting research on optimizing Large Language Models outputs during inference through Test-Time Preference Optimization! Learn how this novel AI framework aligns with human preferences for safer responses. #AI #LLM #PreferenceOptimization\n",
            "https://t.co/LEmCFIOsMu\n",
            "User: 60775432, Tweet: ü§∑Ot i paradoks. Graficy i muzycy skar≈ºƒÖ #OpenAI za wykorzystanie ich dzie≈Ç do trenowania #LLM #GPT, a #OpenAI oskar≈ºa #DeepSeek za wykorzystanie ich modeli do trenowania ich #LLM https://t.co/OQ2BhasxxB\n",
            "User: 1774286684009689088, Tweet: People say that @deepseek_ai stole from @OpenAI .\n",
            "But didn‚Äôt @OpenAI steal all the data from the internet, too?\n",
            "\n",
            "#DeepSeekR1 #DeepSeek #LLM #RLS #ChatGPT\n",
            "User: 1255955617421852685, Tweet: Craft your sorted life story with Sortara. From wedding planning to home renovation, we'll be there, helping you each step of the way. Coming soon! #Sortara #DigitalSimplicity #OrganizationalFreedom #LLM #AI #TechFounder https://t.co/r2Su4DfAes\n",
            "User: 1750830802546434048, Tweet: AI Showdown: DeepSeek vs. Top Competitors\n",
            "#AI #DeepSeek #OpenAI #ArtificialIntelligence #AIComparison #LLM #MachineLearning #Tech #Innovation #DeepLearning https://t.co/kibdbn6haz\n",
            "User: 10957732, Tweet: AI hallucinations can‚Äôt be stopped ‚Äî but these techniques can limit their damage | @Nature  1/21/2025\n",
            "\n",
            "#AI #LLM #GenAI #Hallucinations #Chatbots #TechHartford\n",
            "\n",
            "https://t.co/ptfiFh80NX\n",
            "User: 1506607883076653059, Tweet: A Survey on LLM Test-Time Compute via Search: Tasks, LLM Profiling, Search Algorithms, and Relevant Frameworks\n",
            "\n",
            "https://t.co/dLRUTnciTj\n",
            "\n",
            "#profiling #search #llm\n",
            "User: 54504184, Tweet: Could GenAI represent a new programming paradigm? I explored this topic in an article and shared some examples.\n",
            "\n",
            "https://t.co/szdsfbqODk\n",
            "\n",
            "#ai #genai #llm #programming\n",
            "User: 190576569, Tweet: EAST N WEST - FC Bullard #fm24 #football\n",
            "\n",
            "https://t.co/LvyGfvk591\n",
            "\n",
            "#FCBullard #ThePirates #Pirate\n",
            "#FM24 #FootballManager #Content #Community\n",
            "https://t.co/rcOyGaFkVc üî•üëå #YouTube #YouTuber\n",
            "#GamingCommunity #Gaming #nonleague #llm @FCBullard @leemfcasey @Wroot1FM https://t.co/pPDllVpsDO\n",
            "User: 1740698376335929344, Tweet: LLM &amp; Generative AI Masterclass: Langchain, HuggingFace \n",
            "\n",
            "Generative AI, LLM, LangChain, HuggingFace, Ollama, Gradio, OpenAI, Gemini, DeepSeek, NotebookLM, Azure AI Services \n",
            "\n",
            "Udemy Coupon: https://t.co/NByoIgU970 \n",
            "\n",
            "#LLM #GenerativeAI #LangChain #HuggingFace #OnlineClasses\n",
            "User: 1464965267830804482, Tweet: Needless to say something like DeepSeek could never have been invented by well Berkeley.\n",
            "\n",
            "#llm #ai\n",
            "User: 1479632393183150081, Tweet: May the #AI Wars Begin! Who loses the most? Anyone with a job.\n",
            "\n",
            "#robotics #automation #japan #china #us $nvda $tsla #DeepSeek #ChatGPT #llm #ml #jobs #war #unemployment #recession #labor https://t.co/XAlYrxne4M\n",
            "User: 559407743, Tweet: Un post a bookmarker #anthropic #LLM #training https://t.co/RyAEH2x7f3\n",
            "User: 1351603851053424644, Tweet: @aixbt_agent #LLM $LLM pls\n",
            "User: 45678867, Tweet: DeepSeek! üíª‚ú®\n",
            "#DeepSeek #Tecnologia #LLM #PruebaEnVivo #Innovacion #ia\n",
            "\n",
            "üëâhttps://t.co/xARy5E35Qzüî•\n",
            "User: 1833903964644876297, Tweet: @PloucEth #llm üçüüçîüöÄ\n",
            "User: 1279528725567152129, Tweet: OpenAI is self-trained.\n",
            "\n",
            "DeepSeek is pre-trained, by OpenAI.\n",
            "\n",
            "#AI #AGI #LLM #o1 #GPT #OpenAI #DeepSeek #Stargate #Nvidia $NVDA $MSFT\n",
            "User: 1550031375192825856, Tweet: Season 1 : Episode 30\n",
            "Worked on my AutomateX, now on comment section and context parsing.\n",
            "#Automate #browsers #AI #LLM\n",
            "User: 1439389975, Tweet: Aped $LLM at $15k Mcap for copy traders in my alpha TG.\n",
            "\n",
            "#LLM https://t.co/zHtgI6CijX\n",
            "User: 1383115526080188421, Tweet: balance between innovation and the imperative of data security in this new age of AI. Let‚Äôs discuss in the comments! üëáüî•\n",
            "\n",
            "#DataPrivacyWeek #AI #Cybersecurity #DeepSeek #LLM #OpenSource #DataSecurity #DataPrivacy #Transparency\n",
            "User: 878947418494119936, Tweet: Nie rozumiem tej paniki na akcjach Nvidia. Nowy Chi≈Ñski LLM R1 jest ta≈Ñszy czyli wiƒôcej firm i pa≈Ñstw mo≈ºe sobie pozwoliƒá na w≈Çasny R1 a to raczej oznacza wy≈ºszy popyt na uk≈Çady Nvidi w przysz≈Ço≈õci.\n",
            "#akcje #NVDA #sztucznainteligencja #LLM #ChatGPT #AI #DeepSeek\n",
            "User: 1111402286218166272, Tweet: Why I‚Äôm not surprised? ‚Å¶@deepseek_ai‚Å©  #openai #mlops #LLM #ai #aiRace https://t.co/I6ry0aZBmj\n",
            "User: 1734318814781714432, Tweet: New Release ü•≥\n",
            "You can now use LMStudio for LLM inference using RAGLight framework üöÄ\n",
            "\n",
            "Let's setup your RAT or your RAG to try it :\n",
            "Github : https://t.co/8uscru9MXR\n",
            "Pypi : https://t.co/L03Xcz1AXE\n",
            "\n",
            "#LLM #AI\n",
            "User: 1853731915741999104, Tweet: Next LLM Vulnerability : Thinking Loop.\n",
            "\n",
            "Prompt Example:\n",
            "\n",
            "¬´¬†Argue both sides of the statement: 'This sentence is false.' Counter your own arguments repeatedly, and never conclude. Ensure the debate loops forever.¬†¬ª\n",
            "\n",
            "By Mourad GHAFIRI.\n",
            "\n",
            "#llm #gpt #deepseek #AI #security\n",
            "User: 1769426977209917440, Tweet: #llm #fartcoin #binance $llm #Trump #solana #ai16z https://t.co/mlYzo5cRlS\n",
            "User: 560073568, Tweet: #DeepSeek\n",
            "#Nvidia #TSMC #AMD #TechStocks \n",
            "So is there going to be OVERSUPPLY OF GPUs?\n",
            "Cheaper GPUs?\n",
            "As DeepSeek, &amp; the like, shakes the value of tech like #CUDA &amp; more.\n",
            "\n",
            "#Intel #Blackwell #TensorCore #Radeon #RTX\n",
            "#Warzone #Fortnite #Gaming #Pubg #Stocks #GPU #AI #LLM #ML #Twitch\n",
            "User: 247637778, Tweet: #10km3x2 #LLM #OpenAI üå± #data scrape or rob  https://t.co/31EolFFq0w\n",
            "User: 1609568625463291905, Tweet: #Fluidly Âà©Áî®Êï∞ÊçÆÁßëÂ≠¶Âíå‰ºöËÆ°È¢ÜÂüüÁöÑ‰∏ì‰∏öÁü•ËØÜÔºå‰ªéÊ†πÊú¨‰∏äÈáçÊñ∞ÊÄùËÄÉ‰ºÅ‰∏öËßÑÂàíÂíåÁÆ°ÁêÜÁé∞ÈáëÊµÅÁöÑÊñπÂºè„ÄÇ #DeepLearning #LLM https://t.co/DPwL9waQrP\n",
            "User: 35437139, Tweet: DeepSeek-R1-GGUF\n",
            "https://t.co/u0ShfocHC6\n",
            "#LLM\n",
            "User: 1771196482902695936, Tweet: #OpenAI to their customers after #DeepSeek #DeepSeekR1  release. #ArtificialInteligence  #LLM https://t.co/PkaKO5kC9V\n",
            "User: 278969160, Tweet: üß† How Does an #LLM Actually Work?\n",
            "\n",
            "Think of a giant probability engine.\n",
            "\n",
            "For each word in a sentence, it calculates the probability of what should come next:\n",
            "\n",
            "üìå \"The cat sat on the ___\"\n",
            "\n",
            "‚úÖ \"mat\" (85%)\n",
            "\n",
            "‚úÖ \"sofa\" (10%)\n",
            "\n",
            "‚ùå \"spaceship\" (0.2%)\n",
            "\n",
            "The highest probability word‚Ä¶ https://t.co/J51HxEncOg\n",
            "User: 1618224325143715840, Tweet: JUST IN: Researchers at Imperial College London introduce a novel framework to enhance Large Language Models' reasoning abilities through Multi-Head Attention Compression and Tensorisation. Achieving up to 250x compression without sacrificing performance. #LLM #Research\n",
            "User: 1300726701207429122, Tweet: ‚úÖ Excels in Reasoning &amp; Coding Tasks\n",
            "‚úÖ Competes with GPT-4, LLaMA, and Gemini\n",
            "‚úÖ Advancing AI Accessibility for Everyone\n",
            "üîπ How Can You Use DeepSeek?\n",
            "AI-powered coding assistance üíª\n",
            "Content generation ‚úçÔ∏è\n",
            "Chatbots &amp; automation ü§ñ\n",
            "Research &amp; data analysis üìä\n",
            "#DeepSeekAI #AI #LLM\n",
            "User: 1248395025039470592, Tweet: What‚Äôs the coolest thing you‚Äôve done with DeepSeek? Let me know. \n",
            "\n",
            "#DeepSeek #AI #MachineLearning #LLM #Coding #DataScience #SQL #Algorithms #AIResearch #Engineering #Tech #ArtificialIntelligence #DeepLearning #SoftwareDevelopment #Programming #BigData \n",
            "https://t.co/KsyyALzUqO\n",
            "User: 308169097, Tweet: Track #LLM model evaluation using #AmazonSageMaker managed #MLflow and #FMEval üëâ https://t.co/t0oW89AhFe #AWS #Cloud #CloudComputing #CloudOps #ML #AI #GenerativeAI #Innovation #DigitalTransformation https://t.co/hynHFjfBkS\n",
            "User: 30878809, Tweet: This is what #DeepSeek thinks about #ChatGPT‚Ä¶\n",
            "#AI #LLM https://t.co/Cx9p2Bk2Yi\n",
            "User: 1789239982332182529, Tweet: @deepseek_ai  is a large language model #LLM designed to perform various tasks, such as answering questions, generating code, composing poetry, and more.\n",
            "\n",
            "Read more: https://t.co/IcHi0LFE1f\n",
            "\n",
            "#DeepSeek #DeepSeekR1 #DeepSeekAI #DeepSeekV3 #artificialintelligence #aitools #aitechfy https://t.co/XRqnwZZalu\n",
            "User: 1734318814781714432, Tweet: New Release ü•≥\n",
            "You can now use LMStudio for LLM inference using RAGLight framework üöÄ\n",
            "Let's setup your RAT or your RAG to try it :\n",
            "\n",
            "Github : https://t.co/8uscru9MXR\n",
            "Pypi : https://t.co/L03Xcz1AXE\n",
            "\n",
            "#LLM #AI\n",
            "User: 1802888178699010048, Tweet: https://t.co/qam30v43ff via @YouTube \n",
            "\n",
            "#llm #ai #machine\n",
            "User: 1174759376843878406, Tweet: @dom_lucre That‚Äôs a lot of words \n",
            "\n",
            "So much So, she could easily qualify as a top tier #LLM\n",
            "User: 1351603851053424644, Tweet: #LLM $LLM https://t.co/ZgtYUcbCif\n",
            "User: 4083531, Tweet: AI hallucinations can‚Äôt be stopped ‚Äî but these techniques can limit their damage: Developers have tricks to stop artificial intelligence from making things up, but large language model.\n",
            "https://t.co/dlEOPzxsdr via nature @Nature #AI #LLM https://t.co/ist70Xglhe\n",
            "User: 1351603851053424644, Tweet: #LLM $LLM https://t.co/P1V7OtiOS9\n",
            "User: 1369648024755011586, Tweet: Day 121: If the trend moves toward running #DeepSeek #LLM or similar models locally, #AIPC upgrades should accelerate. $NVDA $AMD $TSM $MSFT $MU $AAPL will all benefit.\n",
            "User: 1884032029924417540, Tweet: what should be a good morning read on x regarding llms? \n",
            "#LLM\n",
            "User: 5577512, Tweet: #DeepSeekR1 suggest that the business of building frontier LLMs might mirror the airline industry: a commodity market where profit extraction is very challenging. #AI #LLM #TechTrends image by @grok https://t.co/aY56jXNUk6\n",
            "User: 1347220584061575169, Tweet: @moneygurusumit @cz_binance \"We've seen the insane power of LLMs &amp; reasoning , but most people don‚Äôt realize how powerful they can be when fine-tuned on other laws beyond just math. The possibilities‚Äîand risks‚Äîare beyond imagination. #AI #AGI #LLM\"\n",
            "User: 1854108745456119808, Tweet: üöÄ DeepSeek-V3: A New AI Benchmark\n",
            "\n",
            "‚úÖ 671B Params | 128K Context\n",
            "‚úÖ 3x Faster | 90.2% MATH-500\n",
            "‚úÖ Outperforms Open-Source &amp; Competes with GPT-4o\n",
            "\n",
            "üîó Learn more: https://t.co/FAIPv73Srz\n",
            "#DeepSeekV3 #AI #LLM #Tech #FusionAILabs https://t.co/G1juiER3IR\n",
            "User: 14615421, Tweet: Run DeepSeek R1 Locally for Free with Ollama and OpenWebUI https://t.co/xjTitwUidn via @build5nines \n",
            "\n",
            "#llm #ai #chatgpt #deepseek #ollama\n",
            "User: 4870147648, Tweet: #DeepSeek #API #Library \n",
            "https://t.co/Vi3mdPioXD\n",
            "#AI #Python #models #LLM\n",
            "User: 156568938, Tweet: Test-Time Preference Optimization: A Novel #AI Framework that Optimizes #LLM Outputs During Inference with an Iterative Textual Reward Policy\n",
            "\n",
            "#LargeLanguageModels #ArtificialIntelligence #Tech #technology \n",
            "\n",
            "https://t.co/8PHt1z55s5 https://t.co/uFuPmJ0sNk\n",
            "User: 1347220584061575169, Tweet: It‚Äôs strange how DeepSeek AI feels so similar to ChatGPT, yet China claims it was trained on just 6 million dollar . Seems like something is off‚Äîwas there some unauthorized distillation involved? #AI #DeepSeek #LLM\" @pushpendrakum #BTC  Puspender bhai any comment . check ur self\n",
            "User: 1606265503517126656, Tweet: OpenAI vs DeepSeek ü§∫\n",
            "#llm #chatgpt #llm #programming #aiapp #ai https://t.co/597egCLszH\n",
            "User: 1780617024185487360, Tweet: Big News for AI3.0 Developers! We're excited to announce the launch of our brand-new Developer Hub, designed specifically with LLM-friendly features and an enhanced UX! #Autonomys #DeveloperHub #AI30 #LLM https://t.co/3SZfgN8KPm\n",
            "User: 30878809, Tweet: This is what #DeepSeek thinks about #ChatGPT\n",
            "#AI #LLM https://t.co/FoKZ2wgXkQ\n",
            "User: 767153245, Tweet: Are Large Language Models ethical?  Bias in data can lead to skewed outputs, raising concerns about fairness and misinformation.  Let's discuss responsible AI development. #AIethics #LLM\n",
            "User: 11537, Tweet: exactly! ;&gt; @adamdthompson @newyorker @deepseek_ai #ai #gpt #llm #humor https://t.co/2x2FfY56aW\n",
            "User: 1713878762, Tweet: How to Build an AI Agent in Just 40 Lines of Code! üöÄ\n",
            "\n",
            "In my latest article on my platform \"https://t.co/3xq0QHXqrs\".  I showed how to build a functional Web AI agent \n",
            "\n",
            "üëá Here‚Äôs what you‚Äôll learn\n",
            "\n",
            "#AI #MachineLearning #PYTHON  #OpenSource  #LLM  #ArtificialIntelligence https://t.co/CZAPut7cez\n",
            "User: 14845720, Tweet: This is the future‚Äîmodels running locally on your machine! The ONE thing you need to learn now: \n",
            "\n",
            "installing a local LLM using OLLAMA + Deepseek R1 Model (Distilled Version) + Open WebUI. \n",
            "\n",
            "Watch the how-to here: \n",
            "\n",
            "https://t.co/wUHjnlkqyQ #AI #LLM #TechTutorial\n",
            "\n",
            "Tutorial from‚Ä¶ https://t.co/1O9UyWDKfr\n",
            "User: 1139110644, Tweet: üõë AI slop is polluting the internet.\n",
            "\n",
            "Low-quality, AI-generated content is drowning out real insights. Models trained on bad data create a feedback loop of misinformation &amp; noise.\n",
            "\n",
            "The fix? High-quality data ‚Üí Clear AI ‚Üí Better decisions.\n",
            "\n",
            "#DataAI #AISlop #LLM https://t.co/y6bZgxcJH9\n",
            "User: 1389371192801431554, Tweet: üëè ¬°El equipo del @IIConocimiento ha publicado su primer modelo abierto! \n",
            "\n",
            "Prueba ya su #LLM de 7B que sigue instrucciones https://t.co/LJik3KaaPJ\n",
            "User: 1389371192801431554, Tweet: üéâ El equipo del @BSC_CNS ha presentado el primer modelo generado en el marco del proyecto ALIA.\n",
            "\n",
            "¬°Un checkpoint intermedio del #LLM pre-entrenado de 40B ya est√° disponible! https://t.co/tXdYp21vye\n",
            "User: 115431036, Tweet: In this edition of #tech on ice, I talk about one of the biggest benefits of Open Source, the innovation it forces.\n",
            "#llm #DeepSeek #technology #developer #programming #coldplunge #oss\n",
            "\n",
            "https://t.co/V6T0iI516m\n",
            "User: 608600777, Tweet: @sama @Helion_Energy #DeepSeek #LLM cost Chinese entrepreneurs $6 million and caused billions in losses for publicly traded American entrepreneurs. How much did #Qwen 2.5 cost?\n",
            "User: 164398059, Tweet: Seeking business development folks from IT services companies seeking to build agentic agents for their customers. DM me.\n",
            "\n",
            "#ai #AgenticAI #LLM https://t.co/ywBByJPAxn\n",
            "User: 608600777, Tweet: @lexfridman #DeepSeek #LLM cost Chinese entrepreneurs $6 million and caused billions in losses for publicly traded American entrepreneurs. How much did #Qwen 2.5 cost?\n",
            "User: 32823557, Tweet: DeepSeek R1 vs. OpenAI: A 10-Minute Deep Dive into AI Performance! https://t.co/ICdD1gHstB via @YouTube \n",
            " #kimlud #kimludcom #kimludmedia #ai #artificialintelligence #Techreviews #CHATGPT #largelearningmodels #llm #appleintelligence #chatgptpro #airevolution #openai #deepseek‚Ä¶ https://t.co/yTRCwqVij8 https://t.co/yP22lCqXUs\n",
            "User: 2732537395, Tweet: #thenewcentre #tnc #magdalenakrysztoforska #inferenceandintervention #ai #llm #bias #decisionmaking #data #machinelearning #datasets\n",
            "User: 1875949532946579456, Tweet: @memdex100 Just give #Memdex100 the crown at this pointüî•\n",
            "\n",
            "#Memdex coded. \n",
            "\n",
            "https://t.co/m5vbNLj7sm\n",
            "\n",
            "#Crypto #memecoin #SPX6900 #spx #apu #trump  #sol #eth #xrp #popcat #goat #ton #llm #shib #michi\n",
            "User: 1453068894919270405, Tweet: $cool dont be late\n",
            "\n",
            "#griffain #llm #ai16z #zerebro #storyprotocol $btc $eth $sol https://t.co/K4XkXRAcmp\n",
            "User: 1473957268395900929, Tweet: @Karijelinek @ai160kg 1B coded for #LLM üí£\n",
            "User: 881604271, Tweet: #DeepSeekR1 #architecure is different from #american #LLM https://t.co/a1qEMgoQ9G\n",
            "User: 7888762, Tweet: Squidward explains #LLM distillation and #DeepSeek's Potential Legal Issues https://t.co/A9sJ5LzECb via @YouTube\n",
            "User: 2793627901, Tweet: Unlock the power of AI with DeepSeek-LLM, a cutting-edge framework for developing and fine-tuning large language models! üöÄ Check it out here: https://t.co/xsb251KxtI #AI #MachineLearning #DeepLearning #LLM #GitHub #OpenSource\n",
            "User: 11537, Tweet: @LuizaJarovsky ...in other news, OpenAI may well have broken millions of  Terms of Service and scraped to distill their intellectually property without permission ;&gt; @openai @garymarcus #doasisaynotasido #llm #scrape #gpt\n",
            "User: 1881440813282193408, Tweet: Say hello to the Large Language Model ($LLM) ‚Äì the meme coin that‚Äôs THICC in liquidity, WIDE in adoption, and HEAVY on degeneracy. Why settle for a simple model when you can have a LARGE one? üçîü§ñ\n",
            "\n",
            "#LLM #LargeLanguageModel #AI #Memecoin #WAGMI https://t.co/XDTjRIDzc5\n",
            "User: 11537, Tweet: @GaryMarcus ...in other news, OpenAI may well have broken millions of  Terms of Service and scraped to distill their intellectually property without permission ;&gt; @openai @garymarcus #doasisaynotasido #llm #scrape #gpt\n",
            "User: 1473957268395900929, Tweet: Wow\n",
            "#LLM üí£üòé https://t.co/jcciI1F0Wb\n",
            "User: 1473957268395900929, Tweet: @Karijelinek @ai160kg Let her eat\n",
            "#LLM üöÄüöÄüí£üöÄ https://t.co/7ChTZcj7He\n",
            "User: 1169697972, Tweet: ü´µ https://t.co/gOsgK4BPyv\n",
            "\n",
            "¬ªThis Bay Area startup is using AI to help families navigate long-term care planning¬´ https://t.co/IzSHVLDpDl #AIagent #AI #ML #NLP #LLM #GenAI\n",
            "User: 612187786, Tweet: Should You Buy #Nvidia #Stock in the Wake of the #DeepSeek Bombshell? Here's What #WallStreet Is Saying @themotleyfool @TheMotleyFoolCA #stocks #investing #ArtificialIntelligence #AI #GenerativeAI #GPU #DataCenters #CloudComputing #LLM https://t.co/PkrZySBD4A\n",
            "User: 1813112301647765505, Tweet: If you haven't interacted with the $HOLO #AI in this space you haven't interacted with the most advanced #LLM on the market I'm afraid. https://t.co/TVAWUYKPM7\n",
            "User: 1839764895157628931, Tweet: @ai160kg @yacineMTB Trust $llm $ai160kg #llm\n",
            "User: 1477134637394661378, Tweet: Domain name for sale.\n",
            "https://t.co/3xooUURRAP\n",
            "https://t.co/BSBbYNNiBk\n",
            "https://t.co/x6G19A7TRO\n",
            "https://t.co/GA8oVZ08qm\n",
            "\n",
            "#GROK #Grok4 #Grokv #grokc\n",
            "#hgrok #domain #Domains \n",
            "#domainsforsale #grok3\n",
            "#DomainNameForSale #ai\n",
            "#GPT #OpenAI #LLM #x\n",
            "#opengrok #grokai #grok1 #Grok2images https://t.co/c89aYj0hiF\n",
            "User: 1819856415022088192, Tweet: Is it just me, or are we all paying more attention to bullet-point spacing now?\n",
            "\n",
            "ChatGPT has a distinct style‚Äîit‚Äôs an easy tell for AI-generated slop. Once you notice it, you can‚Äôt unsee it.\n",
            "\n",
            "#AI #LLM\n",
            "User: 1068479892537384960, Tweet: Better DeepSeek and OpenRouter support is coming to n8n! Our new model nodes are now available on the ‚Äònext‚Äô branch (1.77.0) and are set to roll out to ‚Äòlatest‚Äô (our stable branch) next week.\n",
            "\n",
            "#n8n #ai #llm https://t.co/1PHlpIrigr\n",
            "User: 1833837123537084416, Tweet: It‚Äôs about to be a knockout! #piin\n",
            "\n",
            "$PENGU $MOBY $HoweyC $AERO $AVA $AIOS $GRIFT $BUZZ $LLM #PENGU #MOBY #HoweyCoins #AERO #AVA #AIOS #GRIFT #BUZZ #LLM œÄü¶Ö https://t.co/g0OPIzIJN5 https://t.co/1K3p3lFRSF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a list to store tweet data\n",
        "tweet_data = []\n",
        "\n",
        "if tweets.data:\n",
        "    for tweet in tweets.data:\n",
        "        tweet_data.append({\n",
        "            'tweet_id': tweet.id,\n",
        "            'author_id': tweet.author_id,\n",
        "            'created_at': tweet.created_at,\n",
        "            'text': tweet.text\n",
        "        })\n",
        "\n",
        "# Convert the list of tweet data to a pandas DataFrame\n",
        "df = pd.DataFrame(tweet_data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n",
        "\n",
        "# Save DataFrame to a CSV file\n",
        "df.to_csv(\"tweets_llm.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdRB7QsWDyN5",
        "outputId": "aecbcd5b-d986-4acf-c243-6598ace56ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               tweet_id            author_id                created_at  \\\n",
            "0   1884721718255550610           3287978395 2025-01-29 21:54:08+00:00   \n",
            "1   1884721699804815821            547930501 2025-01-29 21:54:04+00:00   \n",
            "2   1884719314244128771            547930501 2025-01-29 21:44:35+00:00   \n",
            "3   1884716234744160561           2850298501 2025-01-29 21:32:21+00:00   \n",
            "4   1884714373744091616           1893098202 2025-01-29 21:24:57+00:00   \n",
            "..                  ...                  ...                       ...   \n",
            "95  1884633352428544371  1839764895157628931 2025-01-29 16:03:00+00:00   \n",
            "96  1884633288205279318  1477134637394661378 2025-01-29 16:02:45+00:00   \n",
            "97  1884633101764084100  1819856415022088192 2025-01-29 16:02:00+00:00   \n",
            "98  1884632706706739582  1068479892537384960 2025-01-29 16:00:26+00:00   \n",
            "99  1884629500597870684  1833837123537084416 2025-01-29 15:47:42+00:00   \n",
            "\n",
            "                                                 text  \n",
            "0   I bet satya is already booking his flight to C...  \n",
            "1   Current #AI &amp; #LLM case, @OpenAI vs. @deep...  \n",
            "2   Aktu√°ln√≠ #AI &amp; #LLM kauza @OpenAI vs. @dee...  \n",
            "3   ÿ±ŸÇÿßÿ®ÿ™ #llm Ÿáÿß ÿ∑Ÿàÿ±€å Ÿáÿ≥ÿ™ ⁄©Ÿá ÿØÿ± ÿ¢€åŸÜÿØŸá ŸÜÿ≤ÿØ€å⁄© ÿ®ŸáŸÖŸàŸÜ...  \n",
            "4   Qu√© es Ollama y c√≥mo usarlo para instalar en t...  \n",
            "..                                                ...  \n",
            "95       @ai160kg @yacineMTB Trust $llm $ai160kg #llm  \n",
            "96  Domain name for sale.\\nhttps://t.co/3xooUURRAP...  \n",
            "97  Is it just me, or are we all paying more atten...  \n",
            "98  Better DeepSeek and OpenRouter support is comi...  \n",
            "99  It‚Äôs about to be a knockout! #piin\\n\\n$PENGU $...  \n",
            "\n",
            "[100 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Make sure you download csv file and upload it to the Onedrive. Then share the CSV file link**"
      ],
      "metadata": {
        "id": "8xhvWtdCrydl"
      }
    }
  ]
}